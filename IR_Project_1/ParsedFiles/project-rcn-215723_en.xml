<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://cordis.europa.eu">
  <rcn>215723</rcn>
  <acronym>MUSICIAN</acronym>
  <objective>"Cochlear implants (CIs) have been tremendously successful in restoring speech communication for deaf people. However, the enjoyment of music through CIs is still quite limited. The objective of the proposed project ""MUSIc processing for Cochlear Implants based on Auditory and Neural modelling"" (MUSICIAN) is to extract and transmit the most prominent features of music (rhythm, pitch, timbre) such that the listening effort of CI users is reduced and their music appreciation is improved. To this end, we propose to perform fundamental research into measuring and modelling the CI user's music perception and to develop improved processing methods capable of simplifying music signals to their most essential aspects. The project thus addresses the information bottleneck composed of the electrode array and its interface with the auditory nerve and will be help to reduce the perceived distortions of music in CI listeners. Within the proposed programme, two labs with extensive experience in signal processing and audiology, the Institute of Communication Acoustics at Ruhr-Universit√§t Bochum, (beneficiary residing in Bochum, Germany) and the Auditory Engineering Laboratory at McMaster University (partner organisation residing in Hamilton, Canada) will host the experienced researcher Dr. Anil Nagathil who is a pioneer in the development of music processing methods for CIs. The proposed interdisciplinary project will enable Dr. Nagathil to acquire knowledge from several scientific domains and to integrate this expertise into the methods of auditory modelling and music processing. The outcome of this project has substantial commercial impact and the potential to improve the quality of life of hundreds of thousand CI users worldwide."</objective>
  <title>Music Processing for Cochlear Implants Based on Auditory and Neural Modelling</title>
<identifier>H2020MSCAIF2017</identifier>
</project>
